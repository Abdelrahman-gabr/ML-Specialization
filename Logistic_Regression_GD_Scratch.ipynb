{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAtcBWna5GmOZl36lyVtWw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdelrahman-gabr/ML-Specialization-/blob/main/Logistic_Regression_GD_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grediant Descent on Logistic Regression from scratch"
      ],
      "metadata": {
        "id": "MuPfSiMbjfKW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "U1S2rpN2jeg4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
        "y_train = np.array([0, 0, 0, 1, 1, 1])"
      ],
      "metadata": {
        "id": "Wkhk6tW7jn_U"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(fw_b):\n",
        "  return 1/(1+np.exp(-fw_b))"
      ],
      "metadata": {
        "id": "0RVKKxbwjzen"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X,y,w,b):\n",
        "  m = X.shape[0]\n",
        "  cost = 0.0\n",
        "  for i in range(m):\n",
        "    z = sigmoid(np.dot(X[i],w)+b)\n",
        "    cost += -y[i]*np.log(z + 1e-8) - (1-y[i]) * np.log(1-z + 1e-8)\n",
        "  return cost/m"
      ],
      "metadata": {
        "id": "SIlhv2U4luAn"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X,y,w,b):\n",
        "  m,n = X.shape\n",
        "  dj_dw = np.zeros((n,))\n",
        "  dj_db = 0\n",
        "\n",
        "  for i in range(m):\n",
        "    fw_b = sigmoid(np.dot(X[i],w)+b)\n",
        "    error = fw_b - y[i]\n",
        "    for j in range(n):\n",
        "      dj_dw += error * X[i,j]\n",
        "    dj_db += error\n",
        "  return dj_dw/m,dj_db/m"
      ],
      "metadata": {
        "id": "QuXbLK6uj-__"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X,y,win,bin,alpha,iterations):\n",
        "  w = win\n",
        "  b = bin\n",
        "  cost_history = []\n",
        "  for i in range(iterations):\n",
        "    dj_dw,dj_db = compute_gradient(X,y,w,b)\n",
        "    w = w - alpha * dj_dw\n",
        "    b = b - alpha * dj_db\n",
        "    if i % 100000 == 0:\n",
        "      cost = compute_cost(X,y,w,b)\n",
        "      print(f\"Iteration {i:4}: Cost {float(cost):8.5f}\")\n",
        "\n",
        "  return w,b"
      ],
      "metadata": {
        "id": "EBFihoM-k_GW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X,w,b):\n",
        "  p =  sigmoid(np.dot(X,w)+b)\n",
        "  if (p >= 0.5):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "526ywAjmpsap"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros((2,))\n",
        "b = 0.0\n",
        "alpha = 0.001\n",
        "iterations = 1000000\n",
        "w,b = gradient_descent(X_train,y_train,w,b,alpha,iterations)\n",
        "print(f\"w: {w}, b: {b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvMzZooBl3vZ",
        "outputId": "732f5ae2-e566-420c-df67-3b7eab5b4bec"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration    0: Cost  0.69297\n",
            "Iteration 100000: Cost  0.14576\n",
            "Iteration 200000: Cost  0.07656\n",
            "Iteration 300000: Cost  0.05143\n",
            "Iteration 400000: Cost  0.03861\n",
            "Iteration 500000: Cost  0.03086\n",
            "Iteration 600000: Cost  0.02569\n",
            "Iteration 700000: Cost  0.02200\n",
            "Iteration 800000: Cost  0.01923\n",
            "Iteration 900000: Cost  0.01708\n",
            "w: [5.34952856 5.34952856], b: -14.647596210479497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Prediction of 1.11,0.213 = : {predict([[1.11,0.213]],w,b)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAjHg4VPpzJY",
        "outputId": "2c465882-c67f-47b0-aa20-aaeb3f6e9cd9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction of 1.11,0.213 = : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nSxFbib3p_MD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}